{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lzEiYXUX8ZgO",
    "outputId": "703f5bc8-b156-492e-ff86-6952b3beee26"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install numpy requests nlpaug\n",
    "# !pip install comet_ml\n",
    "# !pip install -q pyyaml h5py\n",
    "# !pip install scikit-plot\n",
    "# !pip install tensorflow\n",
    "# !pip install websocket-client==0.47.0\n",
    "# !pip3 install patool\n",
    "# !pip3 install transformers\n",
    "# !pip3 install dask\n",
    "# !pip3 install 'fsspec>=0.3.3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "Q7k5REi98s-Y",
    "outputId": "4236fe5a-b227-42c7-eb90-314f73cead29"
   },
   "outputs": [],
   "source": [
    "# import patoolib\n",
    "# patoolib.extract_archive(\"/content/Archive.zip\", outdir=\"/content/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "o_WJC8Jr8ZgR",
    "outputId": "e8e9ae74-a349-44e1-d8aa-ab44b188419b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positives :  280000\n",
      "Total Negatives :  280000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up before you see this Doctor. The office staff and administration are very unprofessional. I left a message with multiple people regarding my bill, and no one ever called me back. I had to hound them to get an answer about my bill. \\n\\nSecond, and most important, make sure your insurance is going to cover Dr. Goldberg's visits and blood work. He recommended to me that I get a physical, and he knew I was a student because I told him. I got the physical done. Later, I found out my health insurance doesn't pay for preventative visits. I received an $800.00 bill for the blood work. I can't pay for my bill because I'm a student and don't have any cash flow at this current time. I can't believe the Doctor wouldn't give me a heads up to make sure my insurance would cover work that wasn't necessary and was strictly preventative. The office can't do anything to help me cover the bill. In addition, the office staff said the onus is on me to make sure my insurance covers visits. Frustrating situation!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>All the food is great here. But the best thing they have is their wings. Their wings are simply fantastic!!  The \\\"Wet Cajun\\\" are by the best &amp; most popular.  I also like the seasoned salt wings.  Wing Night is Monday &amp; Wednesday night, $0.75 whole wings!\\n\\nThe dining area is nice. Very family friendly! The bar is very nice is well.  This place is truly a Yinzer's dream!!  \\\"Pittsburgh Dad\\\" would love this place n'at!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  \\\n",
       "0  1   \n",
       "1  2   \n",
       "2  1   \n",
       "3  1   \n",
       "4  2   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.  \n",
       "2  I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.  \n",
       "3                                                                                               I'm writing this review to give you a heads up before you see this Doctor. The office staff and administration are very unprofessional. I left a message with multiple people regarding my bill, and no one ever called me back. I had to hound them to get an answer about my bill. \\n\\nSecond, and most important, make sure your insurance is going to cover Dr. Goldberg's visits and blood work. He recommended to me that I get a physical, and he knew I was a student because I told him. I got the physical done. Later, I found out my health insurance doesn't pay for preventative visits. I received an $800.00 bill for the blood work. I can't pay for my bill because I'm a student and don't have any cash flow at this current time. I can't believe the Doctor wouldn't give me a heads up to make sure my insurance would cover work that wasn't necessary and was strictly preventative. The office can't do anything to help me cover the bill. In addition, the office staff said the onus is on me to make sure my insurance covers visits. Frustrating situation!  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                All the food is great here. But the best thing they have is their wings. Their wings are simply fantastic!!  The \\\"Wet Cajun\\\" are by the best & most popular.  I also like the seasoned salt wings.  Wing Night is Monday & Wednesday night, $0.75 whole wings!\\n\\nThe dining area is nice. Very family friendly! The bar is very nice is well.  This place is truly a Yinzer's dream!!  \\\"Pittsburgh Dad\\\" would love this place n'at!!  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Install libraries\n",
    "from comet_ml import Experiment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nlpaug.augmenter.word as nlpaw\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm as tqdm\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "import gc\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Import utility functions\n",
    "# from train_utils import batch_encode\n",
    "\n",
    "# Import matplotlib\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# Import utility functions\n",
    "from data_utils import analyze_dist,augment_sentence,augment_text,combine_toxic_classes,get_relevant_words,undersample_majority\n",
    "\n",
    "# Load the data\n",
    "dask_df_train_valid = dd.read_csv('train.csv',header=None)\n",
    "dask_df_train_valid.npartitions\n",
    "\n",
    "test = pd.read_csv('test.csv',engine='python', encoding='utf-8', error_bad_lines=False,header=None)\n",
    "y_test=test[0]\n",
    "# Check data\n",
    "# 1= Negative , 2 = Positive  \n",
    "\n",
    "df_pos = dask_df_train_valid[(dask_df_train_valid[0] == 2)].compute()\n",
    "print(\"Total positives : \",df_pos.shape[0])\n",
    "\n",
    "df_neg = dask_df_train_valid[(dask_df_train_valid[0] == 1)].compute()\n",
    "print(\"Total Negatives : \",df_neg.shape[0])\n",
    "\n",
    "\n",
    "# Allow us to see full text (not truncated)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "dask_df_train_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzO_OFlR8ZgU"
   },
   "source": [
    "# We have well balanced database\n",
    "### Now we gonna down sample our training dataset as data is huge for our computing resource.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6vgUHMj8ZgU",
    "outputId": "0bcd246a-9c00-4850-b764-ed25857d006a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n",
      "(2800, 2)\n"
     ]
    }
   ],
   "source": [
    "#Test with multiple values \n",
    "downsamplePercentage=(0.5/100)\n",
    "\n",
    "print(downsamplePercentage)\n",
    "\n",
    "df_pos = df_pos.sample(n=(int)((df_pos.shape[0])*downsamplePercentage))\n",
    "\n",
    "df_neg = df_neg.sample(n=(int)((df_neg.shape[0])*downsamplePercentage)) \n",
    "\n",
    "# join downsampled data and shuffle them\n",
    "df = pd.concat([df_pos,df_neg]).sample(frac=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LlViAn488ZgV"
   },
   "outputs": [],
   "source": [
    "# Generate 80-20 train-validation splits\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df[1],\n",
    "                                                      df[0],\n",
    "                                                      train_size=0.8,\n",
    "                                                      stratify=df[0],\n",
    "                                                      shuffle=True,\n",
    "                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wgZr7Rnb8ZgV",
    "outputId": "f8a2733c-b9a8-499c-d6f8-ecc43d6673f2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def batch_encode(tokenizer=[], texts=pd.Series([]), batch_size=256, max_length=512):\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    A function that encodes a batch of texts and returns the texts'\n",
    "    corresponding encodings and attention masks that are ready to be fed \n",
    "    into a pre-trained transformer model.\n",
    "    \n",
    "    Input:\n",
    "        - tokenizer:   Tokenizer object from the PreTrainedTokenizer Class\n",
    "        - texts:       List of strings where each string represents a text\n",
    "        - batch_size:  Integer controlling number of texts in a batch\n",
    "        - max_length:  Integer controlling max number of words to tokenize in a given text\n",
    "    Output:\n",
    "        - input_ids:       sequence of texts encoded as a tf.Tensor object\n",
    "        - attention_mask:  the texts' attention mask encoded as a tf.Tensor object\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer.batch_encode_plus(batch,\n",
    "                                             max_length=max_length,\n",
    "                                             padding='longest', #implements dynamic padding\n",
    "                                             truncation=True,\n",
    "                                             return_attention_mask=True,\n",
    "                                             return_token_type_ids=False\n",
    "                                             )\n",
    "        input_ids.extend(inputs['input_ids'])\n",
    "        attention_mask.extend(inputs['attention_mask'])\n",
    "    \n",
    "    \n",
    "    return tf.convert_to_tensor(input_ids), tf.convert_to_tensor(attention_mask)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate DistilBERT tokenizer...we use the Fast version to optimize runtime\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Encode X_train\n",
    "X_train_ids, X_train_attention = batch_encode(tokenizer, X_train.tolist())\n",
    "\n",
    "# Encode X_valid\n",
    "X_valid_ids, X_valid_attention = batch_encode(tokenizer, X_valid.tolist())\n",
    "\n",
    "\n",
    "\n",
    "# Encode X_test\n",
    "X_test_ids, X_test_attention = batch_encode(tokenizer, test[1].tolist())\n",
    "\n",
    "########## Ensure reproducibility ##########\n",
    "# Set parameters:\n",
    "params = {'MAX_LENGTH': 128,\n",
    "          'EPOCHS': 6,\n",
    "          'LEARNING_RATE': 5e-5,\n",
    "          'FT_EPOCHS': 6,\n",
    "          'OPTIMIZER': 'adam',\n",
    "          'FT_LEARNING_RATE': 2e-5,\n",
    "          'BATCH_SIZE': 64,\n",
    "          'NUM_STEPS': len(X_train.index) // 64,\n",
    "          'DISTILBERT_DROPOUT': 0.2,\n",
    "          'DISTILBERT_ATT_DROPOUT': 0.2,\n",
    "          'LAYER_DROPOUT': 0.2,\n",
    "          'KERNEL_INITIALIZER': 'GlorotNormal',\n",
    "          'BIAS_INITIALIZER': 'zeros',\n",
    "          'POS_PROBA_THRESHOLD': 0.5,          \n",
    "          'ADDED_LAYERS': 'Dense 256, Dense 32, Dropout 0.2',\n",
    "          'LR_SCHEDULE': '5e-5 for 6 epochs, Fine-tune w/ adam for 6 epochs @2e-5',\n",
    "          'FREEZING': 'All DistilBERT layers frozen for 6 epochs, then unfrozen for 6',\n",
    "          'CALLBACKS': '[early_stopping monitoring val_loss w/ patience=0]',\n",
    "          'RANDOM_STATE':42\n",
    "          }\n",
    "\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(params['RANDOM_STATE'])\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(params['RANDOM_STATE'])\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(params['RANDOM_STATE'])\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed=params['RANDOM_STATE'])\n",
    "\n",
    "## Build Model \n",
    "def build_model(transformer, max_length=512):\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    Template for building a model off of the BERT or DistilBERT architecture\n",
    "    for a binary classification task.\n",
    "\n",
    "    Input:\n",
    "      - transformer:  a base Hugging Face transformer model object (BERT or DistilBERT)\n",
    "                      with no added classification head attached.\n",
    "      - max_length:   integer controlling the maximum number of encoded tokens \n",
    "                      in a given sequence.\n",
    "    \n",
    "    Output:\n",
    "      - model:        a compiled tf.keras.Model with added classification layers \n",
    "                      on top of the base pre-trained model architecture.\n",
    "\"\"\"\"\"\"\"\"\"\n",
    "    # Define weight initializer with a random seed to ensure reproducibility\n",
    "    weight_initializer = tf.keras.initializers.GlorotNormal(seed=params['RANDOM_STATE']) \n",
    "    \n",
    "    # Define input layers\n",
    "    input_ids_layer = tf.keras.layers.Input(shape=(max_length,), \n",
    "                                            name='input_ids', \n",
    "                                            dtype='int32')\n",
    "    input_attention_layer = tf.keras.layers.Input(shape=(max_length,), \n",
    "                                                  name='input_attention', \n",
    "                                                  dtype='int32')\n",
    "    \n",
    "    # DistilBERT outputs a tuple where the first element at index 0\n",
    "    # represents the hidden-state at the output of the model's last layer.\n",
    "    # It is a tf.Tensor of shape (batch_size, sequence_length, hidden_size=768).\n",
    "    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n",
    "    \n",
    "    # We only care about DistilBERT's output for the [CLS] token, which is located\n",
    "    # at index 0.  Splicing out the [CLS] tokens gives us 2D data.\n",
    "    cls_token = last_hidden_state[:, 0, :]\n",
    "    \n",
    "    D1 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n",
    "                                 seed=params['RANDOM_STATE']\n",
    "                                )(cls_token)\n",
    "    \n",
    "    X = tf.keras.layers.Dense(256,\n",
    "                              activation='relu',\n",
    "                              kernel_initializer=weight_initializer,\n",
    "                              bias_initializer='zeros'\n",
    "                              )(D1)\n",
    "    \n",
    "    D2 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n",
    "                                 seed=params['RANDOM_STATE']\n",
    "                                )(X)\n",
    "    \n",
    "    X = tf.keras.layers.Dense(32,\n",
    "                              activation='relu',\n",
    "                              kernel_initializer=weight_initializer,\n",
    "                              bias_initializer='zeros'\n",
    "                              )(D2)\n",
    "    \n",
    "    D3 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n",
    "                                 seed=params['RANDOM_STATE']\n",
    "                                )(X)\n",
    "    \n",
    "    # Define a single node that makes up the output layer (for binary classification)\n",
    "    output = tf.keras.layers.Dense(1, \n",
    "                                   activation='sigmoid',\n",
    "                                   kernel_initializer=weight_initializer,  # CONSIDER USING CONSTRAINT\n",
    "                                   bias_initializer='zeros'\n",
    "                                   )(D3)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=params['LEARNING_RATE']), \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79AeVNsi8Zga",
    "outputId": "7100c93c-f095-489d-eab6-afe8a8cf69e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvoir-1c8Zgb",
    "outputId": "5ca993a6-77fd-4147-ff0b-3bb7f71efef5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_layer_norm', 'vocab_transform', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fde981d4fa0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fde981d4fa0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4233 - accuracy: 0.3494 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - 746s 21s/step - loss: 0.4116 - accuracy: 0.3516 - val_loss: -0.9198 - val_accuracy: 0.5000\n",
      "Epoch 2/6\n",
      "35/35 [==============================] - 753s 22s/step - loss: -1.0485 - accuracy: 0.4868 - val_loss: -2.1523 - val_accuracy: 0.5000\n",
      "Epoch 3/6\n",
      "35/35 [==============================] - 775s 22s/step - loss: -2.2307 - accuracy: 0.5216 - val_loss: -3.7052 - val_accuracy: 0.5000\n",
      "Epoch 4/6\n",
      "35/35 [==============================] - 785s 23s/step - loss: -3.9550 - accuracy: 0.4948 - val_loss: -5.8548 - val_accuracy: 0.5000\n",
      "Epoch 5/6\n",
      "35/35 [==============================] - 779s 22s/step - loss: -6.2593 - accuracy: 0.4866 - val_loss: -8.6975 - val_accuracy: 0.5000\n",
      "Epoch 6/6\n",
      "35/35 [==============================] - 749s 22s/step - loss: -8.6349 - accuracy: 0.5173 - val_loss: -12.4506 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "config = DistilBertConfig(dropout=params['DISTILBERT_DROPOUT'], \n",
    "                          attention_dropout=params['DISTILBERT_ATT_DROPOUT'], \n",
    "                          output_hidden_states=True)\n",
    "distilBERT = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n",
    "\n",
    "# Freeze DistilBERT layers to preserve pre-trained weights \n",
    "for layer in distilBERT.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build model\n",
    "model = build_model(distilBERT)\n",
    "\n",
    "# Train Weights of Added Layers and Classification Head \n",
    "\n",
    "# Train the model\n",
    "train_history1 = model.fit(\n",
    "    x = [X_train_ids, X_train_attention],\n",
    "    y = y_train.to_numpy(),\n",
    "    epochs = params['EPOCHS'],\n",
    "    batch_size = params['BATCH_SIZE'],\n",
    "    steps_per_epoch = params['NUM_STEPS'],\n",
    "    validation_data = ([X_valid_ids, X_valid_attention], y_valid.to_numpy()),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b45ABLxnN4Zz",
    "outputId": "62652e88-51c9-4263-b7f1-b69978f3cacb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - ETA: 0s - loss: -21.2095 - accuracy: 0.5197 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - 518s 15s/step - loss: -21.3881 - accuracy: 0.5193 - val_loss: -36.6466 - val_accuracy: 0.5000\n",
      "Epoch 2/6\n",
      "35/35 [==============================] - 521s 15s/step - loss: -37.3816 - accuracy: 0.5034 - val_loss: -41.9790 - val_accuracy: 0.5000\n",
      "Epoch 3/6\n",
      "35/35 [==============================] - 504s 14s/step - loss: -40.1546 - accuracy: 0.5192 - val_loss: -45.8022 - val_accuracy: 0.5000\n",
      "Epoch 4/6\n",
      "35/35 [==============================] - 499s 14s/step - loss: -50.2723 - accuracy: 0.4517 - val_loss: -49.8304 - val_accuracy: 0.5000\n",
      "Epoch 5/6\n",
      "35/35 [==============================] - 500s 14s/step - loss: -52.7707 - accuracy: 0.4584 - val_loss: -54.0312 - val_accuracy: 0.5000\n",
      "Epoch 6/6\n",
      "35/35 [==============================] - 500s 14s/step - loss: -54.5510 - accuracy: 0.5030 - val_loss: -58.4619 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "params['BATCH_SIZE']=16\n",
    "# Unfreeze DistilBERT weights to enable fine-tuning\n",
    "for layer in distilBERT.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Lower the learning rate to prevent destruction of pre-trained weights\n",
    "optimizer = tf.keras.optimizers.Adam(lr=params['FT_LEARNING_RATE'])\n",
    "\n",
    "# Recompile model after unfreezing\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  mode='min',\n",
    "                                                  min_delta=0,\n",
    "                                                  patience=0,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "train_history2 = model.fit(\n",
    "    x = [X_train_ids, X_train_attention],\n",
    "    y = y_train.to_numpy(),\n",
    "    epochs = params['FT_EPOCHS'],\n",
    "    batch_size = params['BATCH_SIZE'],\n",
    "    steps_per_epoch = params['NUM_STEPS'],\n",
    "    validation_data = ([X_valid_ids, X_valid_attention], y_valid.to_numpy()),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "Cffx595COUel",
    "outputId": "bcfc9f47-8fcf-42f1-ae67-48d1e5b11cd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.5\n",
      "ROC-AUC:    0.5\n"
     ]
    }
   ],
   "source": [
    "X_test = test[1][:500]\n",
    "y_test = test[0][:500]\n",
    "X_test_ids, X_test_attention = batch_encode(tokenizer, X_test.tolist())\n",
    "\n",
    "y_pred = model.predict([X_test_ids, X_test_attention])\n",
    "y_pred_thresh = np.where(y_pred >= params['POS_PROBA_THRESHOLD'], 2, 1)\n",
    "\n",
    "# Get evaluation results\n",
    "accuracy = accuracy_score(y_test, y_pred_thresh)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Log the ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test.to_numpy(), y_pred)\n",
    "print('Accuracy:  ', accuracy)    # 0.8801\n",
    "print('ROC-AUC:   ', auc_roc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Contrary to other reviews, I have zero complaints about the service or the prices. I have been getting tire service here for the past 5 years now, and compared to my experience with places like Pep Boys, these guys are experienced and know what they're doing. \\nAlso, this is one place that I do not feel like I am being taken advantage of, just because of my gender. Other auto mechanics have been notorious for capitalizing on my ignorance of cars, and have sucked my bank account dry. But here, my service and road coverage has all been well explained - and let up to me to decide. \\nAnd they just renovated the waiting room. It looks a lot better than it did in previous years.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Last summer I had an appointment to get new tires and had to wait a super long time. I also went in this week for them to fix a minor problem with a tire they put on. They \\\"fixed\\\" it for free, and the very next morning I had the same issue. I called to complain, and the \\\"manager\\\" didn't even apologize!!! So frustrated. Never going back.  They seem overpriced, too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Friendly staff, same starbucks fair you get anywhere else.  Sometimes the lines can get long.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The food is good. Unfortunately the service is very hit or miss. The main issue seems to be with the kitchen, the waiters and waitresses are often very apologetic for the long waits and it's pretty obvious that some of them avoid the tables after taking the initial order to avoid hearing complaints.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Even when we didn't have a car Filene's Basement was worth the bus trip to the Waterfront. I always find something (usually I find 3-4 things and spend about $60) and better still, I am always still wearing the clothes and shoes 3 months later. \\n\\nI kind of suspect this is the best shopping in Pittsburgh; it's much better than the usual department stores, better than Marshall's and TJ Maxx and better than the Saks downtown, even when it has a sale. Selection, bargains AND quality.\\n\\nI like this Filene's better than Gabriel Brothers, which are harder to get to. Gabriel Brothers are a real discount shopper's challenge and I'm afraid I didn't live in Pittsburgh long enough to develop the necessary skills . . . Filene's was still up and running in June 2007 when I left town.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37995</th>\n",
       "      <td>1</td>\n",
       "      <td>If I could give 0...I would.  Don't do it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37996</th>\n",
       "      <td>2</td>\n",
       "      <td>Items Selected:\\nChocolate Cinnamon Horn\\nSmall Cinnamon Crunch Cronut\\nBlueberry Fritter\\nBlueberry Frosted Cake\\nApple Cinnamon Bear Claw\\nCinnamon Crunch Hole, Glazed Hole, Powdered Sugar Hole\\n\\nA new year and a new favorite, the second of back-to-back weeks at Ace Donuts again showed the high quality of the new bakery's goods and this time opting for items not available on my first visit it was a truly excellent quintet that kicked of 2015 - the soft ring beneath blueberry frosting eating more like butter-cake than a doughnut while the fritter and cronut again shined despite selecting smaller versions and different constituents.  More than enough to share, but so good that one may not want to, it was largely due to my early hour of arrival that the Jumbo Bear Claw stuffed with ample amounts of cinnamon apples outshined any similar pastry in the city and although the combination of rich chocolate and substantial notes of cinnamon may not appeal to every palate the crispy exterior and soft insides of the gnarly horn was a veritable cornucopia of flavor, the warm delivery making the aromatics even more impactful and the chocolate just messy enough to justify the use of a fork and knife.\\n\\nUndoubtedly the best all-around doughnuttery in Las Vegas - Artisan, Old School, or Otherwise.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37997</th>\n",
       "      <td>1</td>\n",
       "      <td>Expensive lunch meals.  Fried pickles were good.  Waitress messed up 2 orders out of 4.  Don't think I'll return.  Asked for no cheese waitress joked extra cheese, then brought my meal with cheese.  Better places to eat in area.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37998</th>\n",
       "      <td>1</td>\n",
       "      <td>Highly overpriced and food was cold. Our waitress seemed confused and didn't know the menu. She had no idea about gluten free. The gluten free bun was awful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37999</th>\n",
       "      <td>1</td>\n",
       "      <td>I have been using this company for 11 months.  Ryan would come out every other week and do what he needed to be done. Very little was required as I have desert landscaping and pretty much maintained it myself.  Just needed blowing and general light cleanup.  Ryan was very thorough.\\nThen his brother, I believe, would  come out.  I would have to watch him as if I was not looking, it would be a pretty much \\\"hit and run\\\" literally.\\nI was expecting them Friday.  No show, no call as they never call when they cannot make it.  I have to call them and ask where they are or if they are coming.   Finally a text back saying they will be there Monday as they are running late.\\n\\nMonday comes and again no call no show.  I texted them...no answer...I was very upset at this point as I asked if they would trim a tree that is coming into my yard from a neighbor.  Mind you, there is very little to do here...no grass...no weeds..no plants to constantly trim.  I felt that I asked them to trim a tree and they could not be bothered.\\n\\nI am extremely disappointed in this company as they start out fine and as it continues, they seem to take their customer's for granted.  NO COMMUNICATION...NOT EVEN A CALL WHEN THEY CANNOT COME.   \\n\\nSORRY RYAN, I WILL TAKE MY BUSINESS ELSEWHERE.  AS A BUSINESS OWNER, YOU SHOULD KNOW BETTER!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      2   \n",
       "3      1   \n",
       "4      2   \n",
       "...   ..   \n",
       "37995  1   \n",
       "37996  2   \n",
       "37997  1   \n",
       "37998  1   \n",
       "37999  1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Contrary to other reviews, I have zero complaints about the service or the prices. I have been getting tire service here for the past 5 years now, and compared to my experience with places like Pep Boys, these guys are experienced and know what they're doing. \\nAlso, this is one place that I do not feel like I am being taken advantage of, just because of my gender. Other auto mechanics have been notorious for capitalizing on my ignorance of cars, and have sucked my bank account dry. But here, my service and road coverage has all been well explained - and let up to me to decide. \\nAnd they just renovated the waiting room. It looks a lot better than it did in previous years.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Last summer I had an appointment to get new tires and had to wait a super long time. I also went in this week for them to fix a minor problem with a tire they put on. They \\\"fixed\\\" it for free, and the very next morning I had the same issue. I called to complain, and the \\\"manager\\\" didn't even apologize!!! So frustrated. Never going back.  They seem overpriced, too.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Friendly staff, same starbucks fair you get anywhere else.  Sometimes the lines can get long.  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The food is good. Unfortunately the service is very hit or miss. The main issue seems to be with the kitchen, the waiters and waitresses are often very apologetic for the long waits and it's pretty obvious that some of them avoid the tables after taking the initial order to avoid hearing complaints.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Even when we didn't have a car Filene's Basement was worth the bus trip to the Waterfront. I always find something (usually I find 3-4 things and spend about $60) and better still, I am always still wearing the clothes and shoes 3 months later. \\n\\nI kind of suspect this is the best shopping in Pittsburgh; it's much better than the usual department stores, better than Marshall's and TJ Maxx and better than the Saks downtown, even when it has a sale. Selection, bargains AND quality.\\n\\nI like this Filene's better than Gabriel Brothers, which are harder to get to. Gabriel Brothers are a real discount shopper's challenge and I'm afraid I didn't live in Pittsburgh long enough to develop the necessary skills . . . Filene's was still up and running in June 2007 when I left town.  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...  \n",
       "37995                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         If I could give 0...I would.  Don't do it.  \n",
       "37996                          Items Selected:\\nChocolate Cinnamon Horn\\nSmall Cinnamon Crunch Cronut\\nBlueberry Fritter\\nBlueberry Frosted Cake\\nApple Cinnamon Bear Claw\\nCinnamon Crunch Hole, Glazed Hole, Powdered Sugar Hole\\n\\nA new year and a new favorite, the second of back-to-back weeks at Ace Donuts again showed the high quality of the new bakery's goods and this time opting for items not available on my first visit it was a truly excellent quintet that kicked of 2015 - the soft ring beneath blueberry frosting eating more like butter-cake than a doughnut while the fritter and cronut again shined despite selecting smaller versions and different constituents.  More than enough to share, but so good that one may not want to, it was largely due to my early hour of arrival that the Jumbo Bear Claw stuffed with ample amounts of cinnamon apples outshined any similar pastry in the city and although the combination of rich chocolate and substantial notes of cinnamon may not appeal to every palate the crispy exterior and soft insides of the gnarly horn was a veritable cornucopia of flavor, the warm delivery making the aromatics even more impactful and the chocolate just messy enough to justify the use of a fork and knife.\\n\\nUndoubtedly the best all-around doughnuttery in Las Vegas - Artisan, Old School, or Otherwise.  \n",
       "37997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Expensive lunch meals.  Fried pickles were good.  Waitress messed up 2 orders out of 4.  Don't think I'll return.  Asked for no cheese waitress joked extra cheese, then brought my meal with cheese.  Better places to eat in area.  \n",
       "37998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Highly overpriced and food was cold. Our waitress seemed confused and didn't know the menu. She had no idea about gluten free. The gluten free bun was awful.  \n",
       "37999  I have been using this company for 11 months.  Ryan would come out every other week and do what he needed to be done. Very little was required as I have desert landscaping and pretty much maintained it myself.  Just needed blowing and general light cleanup.  Ryan was very thorough.\\nThen his brother, I believe, would  come out.  I would have to watch him as if I was not looking, it would be a pretty much \\\"hit and run\\\" literally.\\nI was expecting them Friday.  No show, no call as they never call when they cannot make it.  I have to call them and ask where they are or if they are coming.   Finally a text back saying they will be there Monday as they are running late.\\n\\nMonday comes and again no call no show.  I texted them...no answer...I was very upset at this point as I asked if they would trim a tree that is coming into my yard from a neighbor.  Mind you, there is very little to do here...no grass...no weeds..no plants to constantly trim.  I felt that I asked them to trim a tree and they could not be bothered.\\n\\nI am extremely disappointed in this company as they start out fine and as it continues, they seem to take their customer's for granted.  NO COMMUNICATION...NOT EVEN A CALL WHEN THEY CANNOT COME.   \\n\\nSORRY RYAN, I WILL TAKE MY BUSINESS ELSEWHERE.  AS A BUSINESS OWNER, YOU SHOULD KNOW BETTER!!!!  \n",
       "\n",
       "[38000 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDVNwf-eOXo1"
   },
   "outputs": [],
   "source": [
    "In [ ]:\n",
    "# Build train_history\n",
    "history_df1 = pd.DataFrame(train_history1.history)\n",
    "history_df2 = pd.DataFrame(train_history2.history)\n",
    "history_df = history_df1.append(history_df2, ignore_index=True)\n",
    "\n",
    "# Plot training and validation loss over each epoch\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot()\n",
    "plt.title(label='Training + Validation Loss Over Time', fontsize=17, pad=19)\n",
    "plt.xlabel('Epoch', labelpad=14, fontsize=14)\n",
    "plt.ylabel('Binary Crossentropy Loss', labelpad=16, fontsize=14)\n",
    "print(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('figures/balanced_trainvalloss.png', dpi=300.0, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-QN00ddpOaX2"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "skplt.metrics.plot_confusion_matrix(y_test.to_list(),\n",
    "                                    y_pred_thresh.tolist(),\n",
    "                                    figsize=(6,6),\n",
    "                                    text_fontsize=14)\n",
    "plt.title(label='Test Confusion Matrix', fontsize=20, pad=17)\n",
    "plt.xlabel('Predicted Label', labelpad=14)\n",
    "plt.ylabel('True Label', labelpad=14)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('figures/balanced_confusionmatrix.png', dpi=300.0, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aKEN8jzOw1e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save model\n",
    "tf.saved_model.save(model, 'models/balanced_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cr98RFKacxjt"
   },
   "outputs": [],
   "source": [
    "\n",
    "def augment_sentence(sentence, aug, num_threads):\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    Constructs a new sentence via text augmentation.\n",
    "    \n",
    "    Input:\n",
    "        - sentence:     A string of text\n",
    "        - aug:          An augmentation object defined by the nlpaug library\n",
    "        - num_threads:  Integer controlling the number of threads to use if\n",
    "                        augmenting text via CPU\n",
    "    Output:\n",
    "        - A string of text that been augmented\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    return aug.augment(sentence, num_thread=num_threads)\n",
    "    \n",
    "\n",
    "\n",
    "def augment_text(df, aug, num_threads, num_times, review_type):\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    Takes a pandas DataFrame and augments its text data.\n",
    "    \n",
    "    Input:\n",
    "        - df:            A pandas DataFrame containing the columns:\n",
    "                                - 'comment_text' containing strings of text to augment.\n",
    "                                - 'isToxic' binary target variable containing 0's and 1's.\n",
    "        - aug:           Augmentation object defined by the nlpaug library.\n",
    "        - num_threads:   Integer controlling number of threads to use if augmenting\n",
    "                         text via CPU\n",
    "        - num_times:     Integer representing the number of times to augment text.\n",
    "        - review_type:   Type of review to augment (postive or negative)\n",
    "    Output:\n",
    "        - df:            Copy of the same pandas DataFrame with augmented data \n",
    "                         appended to it and with rows randomly shuffled.\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    \n",
    "    # Get rows of data to augment\n",
    "    to_augment = df[df[0]==review_type]\n",
    "    to_augmentX = to_augment[1]\n",
    "    to_augmentY = np.ones(len(to_augmentX.index) * num_times, dtype=np.int8)\n",
    "    \n",
    "    # Build up dictionary containing augmented data\n",
    "    aug_dict = {1:[], 0:to_augmentY}\n",
    "    for i in tqdm(range(num_times)):\n",
    "        augX = [augment_sentence(x, aug, num_threads) for x in to_augmentX]\n",
    "        aug_dict[1].extend(augX)\n",
    "    \n",
    "    # Build DataFrame containing augmented data\n",
    "    aug_df = pd.DataFrame.from_dict(aug_dict)\n",
    "    \n",
    "    return df.append(aug_df, ignore_index=True).sample(frac=1, random_state=42)\n",
    "    \n",
    "\n",
    "    \n",
    "# Define nlpaug augmentation object \n",
    "aug10p = nlpaw.ContextualWordEmbsAug(model_path='bert-base-uncased', aug_min=1, aug_p=0.1, action=\"substitute\")\n",
    "\n",
    "# Augment Negative class ([0] == 1)\n",
    "df_train_valid = augment_text(dask_df_train_valid, aug10p, num_threads=8, num_times=3,review_type=1)\n",
    "# Augment Positive class ([0] == 1)\n",
    "df_train_valid = augment_text(dask_df_train_valid, aug10p, num_threads=8, num_times=3,review_type=2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "history_visible": true,
   "name": "Yelp_Reviews_Exploratory_Data_Analysis .ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
